"""initial migration

Revision ID: 6e7ac8989fef
Revises: 533f802658e7
Create Date: 2025-11-23 09:00:25.042395

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '6e7ac8989fef'
down_revision: Union[str, Sequence[str], None] = '533f802658e7'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    """Upgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('document_jobs', schema=None) as batch_op:
        batch_op.alter_column('attempt_count',
               existing_type=sa.INTEGER(),
               server_default=sa.text('0'),
               existing_nullable=False)
        batch_op.alter_column('max_retries',
               existing_type=sa.INTEGER(),
               server_default=sa.text('3'),
               existing_nullable=False)
        batch_op.alter_column('retry_delay_secs',
               existing_type=sa.INTEGER(),
               server_default=sa.text('30'),
               existing_nullable=False)
        batch_op.alter_column('timeout_after_secs',
               existing_type=sa.INTEGER(),
               server_default=sa.text('600'),
               existing_nullable=False)
        batch_op.alter_column('triggered_by',
               existing_type=sa.INTEGER(),
               type_=sa.UUID(),
               existing_nullable=True,
               postgresql_using='triggered_by::text::uuid')
               
        batch_op.alter_column('is_idempotent',
               existing_type=sa.BOOLEAN(),
               server_default=sa.text('true'),
               existing_nullable=False)
        batch_op.create_index('ix_document_jobs_doc_type', ['document_id', 'job_type'], unique=False)
        batch_op.create_index(batch_op.f('ix_document_jobs_triggered_by'), ['triggered_by'], unique=False)
        batch_op.create_index('ix_document_jobs_unique_running', ['document_id', 'job_type', 'status'], unique=True, postgresql_where=sa.text("status = 'running'"))
        batch_op.create_foreign_key(None, 'document_jobs', ['triggered_by'], ['id'], ondelete='SET NULL')

    with op.batch_alter_table('documents', schema=None) as batch_op:
        batch_op.alter_column('content_type',
               existing_type=sa.VARCHAR(length=100),
               nullable=False)
        batch_op.drop_index(batch_op.f('ix_documents_id'))
        batch_op.drop_index(batch_op.f('ix_documents_processed_at'))
        batch_op.drop_index(batch_op.f('ix_documents_processing_result'))
        batch_op.drop_index(batch_op.f('ix_documents_processing_stage'))
        batch_op.drop_index(batch_op.f('ix_documents_processing_status'))
        batch_op.drop_index(batch_op.f('ix_documents_storage_key_prefix'), postgresql_ops={'storage_key': 'text_pattern_ops'})
        batch_op.drop_index(batch_op.f('ix_documents_trace_id'))
        batch_op.drop_index(batch_op.f('ix_documents_user_status_created'))
        batch_op.drop_index(batch_op.f('ix_documents_user_storage_status'))
        batch_op.create_index(batch_op.f('ix_documents_created_at'), ['created_at'], unique=False)
        batch_op.create_index(batch_op.f('ix_documents_deleted_at'), ['deleted_at'], unique=False)
        batch_op.create_index('ix_documents_filename', ['filename'], unique=False)
        batch_op.create_index('ix_documents_user_created', ['user_id', 'created_at'], unique=False)
        batch_op.create_index('ix_documents_user_deleted', ['user_id', 'deleted_at'], unique=False)
        batch_op.drop_column('error_message')
        batch_op.drop_column('processing_progress')
        batch_op.drop_column('processing_stage')
        batch_op.drop_column('processed_at')
        batch_op.drop_column('trace_id')
        batch_op.drop_column('processing_result')
        batch_op.drop_column('processing_status')

    # ### end Alembic commands ###


def downgrade() -> None:
    """Downgrade schema."""
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('documents', schema=None) as batch_op:
        batch_op.add_column(sa.Column('processing_status', sa.VARCHAR(), server_default=sa.text("'pending'::character varying"), autoincrement=False, nullable=False, comment='处理状态：等待中、处理中、成功、失败、超时'))
        batch_op.add_column(sa.Column('processing_result', sa.VARCHAR(), server_default=sa.text("'pending'::character varying"), autoincrement=False, nullable=False, comment='最终处理结果：成功、失败、部分成功等'))
        batch_op.add_column(sa.Column('trace_id', sa.VARCHAR(length=64), autoincrement=False, nullable=True, comment='分布式追踪ID，用于日志链路分析'))
        batch_op.add_column(sa.Column('processed_at', postgresql.TIMESTAMP(timezone=True), autoincrement=False, nullable=True, comment='处理完成时间（任务完全完成）'))
        batch_op.add_column(sa.Column('processing_stage', sa.VARCHAR(), server_default=sa.text("'pending'::character varying"), autoincrement=False, nullable=False, comment='处理阶段：待处理、提取文本、分块、向量化、存储向量、完成'))
        batch_op.add_column(sa.Column('processing_progress', postgresql.JSONB(astext_type=sa.Text()), server_default=sa.text("'{}'::jsonb"), autoincrement=False, nullable=True, comment='处理进度详情：各阶段的开始时间、结束时间、状态、错误信息'))
        batch_op.add_column(sa.Column('error_message', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.drop_index('ix_documents_user_deleted')
        batch_op.drop_index('ix_documents_user_created')
        batch_op.drop_index('ix_documents_filename')
        batch_op.drop_index(batch_op.f('ix_documents_deleted_at'))
        batch_op.drop_index(batch_op.f('ix_documents_created_at'))
        batch_op.create_index(batch_op.f('ix_documents_user_storage_status'), ['user_id', 'storage_status'], unique=False)
        batch_op.create_index(batch_op.f('ix_documents_user_status_created'), ['user_id', 'storage_status', 'created_at'], unique=False)
        batch_op.create_index(batch_op.f('ix_documents_trace_id'), ['trace_id'], unique=False)
        batch_op.create_index(batch_op.f('ix_documents_storage_key_prefix'), ['storage_key'], unique=False, postgresql_ops={'storage_key': 'text_pattern_ops'})
        batch_op.create_index(batch_op.f('ix_documents_processing_status'), ['processing_status'], unique=False)
        batch_op.create_index(batch_op.f('ix_documents_processing_stage'), ['processing_stage'], unique=False)
        batch_op.create_index(batch_op.f('ix_documents_processing_result'), ['processing_result'], unique=False)
        batch_op.create_index(batch_op.f('ix_documents_processed_at'), ['processed_at'], unique=False)
        batch_op.create_index(batch_op.f('ix_documents_id'), ['id'], unique=False)
        batch_op.alter_column('content_type',
               existing_type=sa.VARCHAR(length=100),
               nullable=True)

    with op.batch_alter_table('document_jobs', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.drop_index('ix_document_jobs_unique_running', postgresql_where=sa.text("status = 'running'"))
        batch_op.drop_index(batch_op.f('ix_document_jobs_triggered_by'))
        batch_op.drop_index('ix_document_jobs_doc_type')
        batch_op.alter_column('is_idempotent',
               existing_type=sa.BOOLEAN(),
               server_default=None,
               existing_nullable=False)
        batch_op.alter_column('triggered_by',
               existing_type=sa.UUID(),
               type_=sa.INTEGER(),
               existing_nullable=True)
        batch_op.alter_column('timeout_after_secs',
               existing_type=sa.INTEGER(),
               server_default=None,
               existing_nullable=False)
        batch_op.alter_column('retry_delay_secs',
               existing_type=sa.INTEGER(),
               server_default=None,
               existing_nullable=False)
        batch_op.alter_column('max_retries',
               existing_type=sa.INTEGER(),
               server_default=None,
               existing_nullable=False)
        batch_op.alter_column('attempt_count',
               existing_type=sa.INTEGER(),
               server_default=None,
               existing_nullable=False)

    # ### end Alembic commands ###
